{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Transform Load Project\n",
    "### Team Biscotti\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependacies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pymongo\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import func\n",
    "\n",
    "# postgres pasword\n",
    "import postgres_password from config as password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Extract\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping \n",
    "* Splinter\n",
    "* Beautiful Soup\n",
    "* Requests\n",
    "* webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path and open browser window\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# establish url\n",
    "url = 'https://quotes.toscrape.com/'\n",
    "\n",
    "# visit site\n",
    "browser.visit(url)\n",
    "\n",
    "# grab page html\n",
    "html = browser.html\n",
    "\n",
    "# create soup object\n",
    "soup = BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loop through pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the initial list to store the data\n",
    "quotes_list = []\n",
    "\n",
    "# initialize \"next\" object to start while loop\n",
    "Next = True\n",
    "\n",
    "# loop to go thru pages while next button count is greater than zero\n",
    "while Next==True :\n",
    "    # grab page html\n",
    "    html = browser.html\n",
    "    # create soup object\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    # isolate the quote boxes for scraping\n",
    "    boxes = soup.find_all('div',class_='quote')\n",
    "    \n",
    "    # for loop to click \"about author\" > get data > back > get box data\n",
    "    for box in boxes:\n",
    "        # initialize the mini dictionary\n",
    "        quote_mini = {}\n",
    "      \n",
    "        # identify where to click on \"about author\"\n",
    "        target = box.a['href']\n",
    "        \n",
    "        # click \"about author\" button\n",
    "        browser.links.find_by_href(target).click()\n",
    "        \n",
    "        # get page html\n",
    "        html = browser.html\n",
    "        \n",
    "        # create a soup object\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        \n",
    "        # add values for author to the mini dict\n",
    "        quote_mini['author_name'] = soup.find('h3',class_='author-title').text\n",
    "        quote_mini['birth_date'] = soup.find('span',class_='author-born-date').text\n",
    "        quote_mini['birth_place'] = soup.find('span',class_='author-born-location').text\n",
    "        quote_mini['description'] = soup.find('div',class_='author-description').text.replace('\\n', '')\n",
    "        \n",
    "        # click back button\n",
    "        browser.back()\n",
    "               \n",
    "        ## Grab quote box values for mini dict\n",
    "        \n",
    "        # add quote to the mini dict\n",
    "        quote_mini['quote_text'] = box.span.text     \n",
    "        \n",
    "        # remove extra spaces, commas, and new line text that is not needed\n",
    "        quote_tags = box.div.text.replace('\\n',',').split(',')\n",
    "        do_not_want = ['','            Tags:','            ']\n",
    "        \n",
    "        # add quote to the mini dict\n",
    "        quote_mini['quote_tags'] = [tag for tag in quote_tags if tag not in do_not_want]\n",
    "        \n",
    "        # append completed mini dict to the quotes list\n",
    "        quotes_list.append(quote_mini)\n",
    "                \n",
    "    # look for next button true/false for while loop condition        \n",
    "    if browser.links.find_by_text('Next '):\n",
    "        Next = True\n",
    "        # click next button to move to next page \n",
    "        browser.links.find_by_text('Next ').click()\n",
    "    else:\n",
    "        # if no next button end loop\n",
    "        Next = False\n",
    "\n",
    "# if initialized at the begining of loop do we need at teh end?\n",
    "#    html = browser.html\n",
    "#    soup = BeautifulSoup(html,'html.parser')\n",
    "#    boxes = soup.find_all('div',class_='quote')\n",
    "\n",
    "# quite browser session and driver\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check results of web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check web scraping results\n",
    "quotes_list[-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check author info web scraping results\n",
    "for i in quotes_list:\n",
    "    print(i['author_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-relational Database\n",
    "* MongoDB\n",
    "* Pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection to mongo database\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# create new data base\n",
    "db = client.quotes_db\n",
    "\n",
    "# drop the collection if it already exists\n",
    "db.quotes.drop()\n",
    "\n",
    "# instert our list of mini dictionaries from scraping\n",
    "db.quotes.insert_many(quotes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check results of Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all quotes in collection\n",
    "list_of_quotes = list(db.quotes.find())\n",
    "print(list_of_quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Transform\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data\n",
    "* Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use list of dict to create dataframe\n",
    "main_quote_df = pd.DataFrame(list_of_quotes)\n",
    "\n",
    "# drop mongo id field\n",
    "main_quote_df = main_quote_df.drop(['_id'],axis=1)\n",
    "\n",
    "# change index value to = quote id\n",
    "main_quote_df['quote_id'] = main_quote_df.index\n",
    "\n",
    "#check results\n",
    "main_quote_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create Tags table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_quote_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3916458d0ed5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Isolate tags df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_quote_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'quote_tags'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# break the tags list in each row into individal rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_quote_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'quote_tags'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'main_quote_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Isolate tags df\n",
    "tags = main_quote_df['quote_tags']\n",
    "\n",
    "# break the tags list in each row into individal rows\n",
    "tags = main_quote_df.explode('quote_tags')\n",
    "tags = tags[['quote_tags','quote_id']]\n",
    "tags = tags.set_index('quote_id')\n",
    "\n",
    "# rename column to tags\n",
    "tags.rename(columns = {'quote_tags':'tags'},inplace=True)\n",
    "# check results\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create Quotes Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate only relevant columns from main df\n",
    "quotes_df = main_quote_df[['author_name', 'quote_text','quote_id']]\n",
    "\n",
    "# eleminate index value by setting index to id#\n",
    "quotes_df = quotes_df.set_index('quote_id')\n",
    "\n",
    "# check results\n",
    "quotes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create Author Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate only relevant columns from main df\n",
    "author_df = main_quote_df[['author_name','birth_date','birth_place','description']]\n",
    "\n",
    "# drop duplicate authors\n",
    "author_df = author_df.drop_duplicates(keep='first')\n",
    "\n",
    "# check results\n",
    "author_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational database\n",
    "* Pandas\n",
    "* SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create engine to postgres\n",
    "engine = create_engine(f'postgresql://postgres:{password}@localhost:5432/sql-challenge')\n",
    "\n",
    "# use engine to connect to existing tables/db\n",
    "Database = automap_base( )\n",
    "Database.prepare(engine, reflect=True)\n",
    "\n",
    "# View all of the classes/tables that automap found\n",
    "Database.classes.keys( )\n",
    "\n",
    "# Save references to each table (capital because they are considered classes) \n",
    "Tags = Database.classes.table_name\n",
    "Quots = Database.classes.table_name\n",
    "Author = Database.classes.table_name\n",
    "\n",
    "# Create our session (link) from Python to the DB\n",
    "session = Session(bind=engine)\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Use  get_columns in order write queries later\n",
    "inspector.get_columns('table_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
