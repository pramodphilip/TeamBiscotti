{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependacies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pymongo\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path and open browser window\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# establish url\n",
    "url = 'https://quotes.toscrape.com/'\n",
    "\n",
    "# visit site\n",
    "browser.visit(url)\n",
    "\n",
    "# grab page html\n",
    "html = browser.html\n",
    "\n",
    "# create soup object\n",
    "soup = BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the initial list to store the data\n",
    "quotes_list = []\n",
    "\n",
    "# loop to go thru pages while next button count is greater than zero\n",
    "while len(browser.links.find_by_partial_text('Next ')) > 0:\n",
    "    # grab page html\n",
    "    html = browser.html\n",
    "    # create soup object\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    # isolate the quote boxes for scraping\n",
    "    boxes = soup.find_all('div',class_='quote')\n",
    "    \n",
    "    # for loop to click \"about author\" > get data > back > get box data\n",
    "    for box in boxes:\n",
    "        # initialize the mini dictionary\n",
    "        quote_mini = {}\n",
    "        \n",
    "        # identify where to click on \"about author\"\n",
    "        target = box.a['href']\n",
    "        # click button\n",
    "        browser.links.find_by_href(target).click()\n",
    "        \n",
    "        # get page html\n",
    "        html = browser.html\n",
    "        \n",
    "        # create a soup object\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        \n",
    "        # add values for author to the mini dict\n",
    "        quote_mini['author_name'] = soup.find('h3',class_='author-title').text\n",
    "        quote_mini['birth_date'] = soup.find('span',class_='author-born-date').text\n",
    "        quote_mini['birth_place'] = soup.find('span',class_='author-born-location').text\n",
    "        quote_mini['description'] = soup.find('div',class_='author-description').text.replace('\\n', '')\n",
    "        \n",
    "        # click back button\n",
    "        browser.back()\n",
    "        \n",
    "        # Grab quote box values for mini dict\n",
    "        \n",
    "        # add quote to the mini dict\n",
    "        quote_mini['quote_text'] = box.span.text\n",
    "        \n",
    "        # remove extra spaces, commas, and new line text that is not needed\n",
    "        quote_tags = box.div.text.replace('\\n',',').split(',')\n",
    "        do_not_want = ['','            Tags:','            ']\n",
    "        \n",
    "        # add quote to the mini dict\n",
    "        quote_mini['quote_tags'] = [tag for tag in quote_tags if tag not in do_not_want]\n",
    "\n",
    "        # append completed mini dict to the quotes list\n",
    "        quotes_list.append(quote_mini)\n",
    "        \n",
    "    # click next button to move to next page    \n",
    "    browser.links.find_by_text('Next ').click()\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection to mongo database\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data base\n",
    "db = client.quotes_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the collection if it already exists\n",
    "db.quotes.drop()\n",
    "# instert our list of mini dictionaries from scraping\n",
    "db.quotes.insert_many(quotes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all quotes in collection\n",
    "list_of_quotes = list(db.quotes.find())\n",
    "#print(list_of_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use list of dict to create dataframe\n",
    "quote_df = pd.DataFrame(list_of_quotes)\n",
    "\n",
    "# drop mongo id field\n",
    "quote_df = quote_df.drop(['_id'],axis=1)\n",
    "\n",
    "# change index value to = quote id\n",
    "quote_df['quote_id'] = quote_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate tags df\n",
    "tags = quote_df['quote_tags']\n",
    "\n",
    "# break the tags list in each row into individal rows\n",
    "tags = quote_df.explode('quote_tags')\n",
    "tags = tags[['quote_tags','quote_id']]\n",
    "tags = tags.set_index('quote_id')\n",
    "\n",
    "# rename column to tags\n",
    "tags.rename(columns = {'quote_tags':'tags'},inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
